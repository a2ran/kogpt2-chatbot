{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d01677c4",
   "metadata": {},
   "source": [
    "한국어 문장예측모델인 skt/kogpt2을 fine-tuning해<br>\n",
    "사용자가 심리상담 주제 관련 **문장**을 입력하면,<br>\n",
    "대화의 **주제와 응답**을 출력하는 챗봇 모델을 구축했습니다.\n",
    "\n",
    "출처: 웰니스 대화 스크립트 데이터셋(AI Hub, 2019) <br>\n",
    "Kogpt2 모델 https://github.com/SKT-AI/KoGPT2\n",
    "\n",
    "<img src = 'img/0.png' width = '70%'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21e52fd",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "<img src = 'img/1.png'>\n",
    "\n",
    "<img src = 'img/2.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c7b473",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce0a4aa",
   "metadata": {},
   "source": [
    "<img src = 'img/3.png'>\n",
    "\n",
    "<img src = 'img/4.png'>\n",
    "\n",
    "<img src = 'img/5.png'>\n",
    "\n",
    "<img src = 'img/6.png'>\n",
    "\n",
    "<img src = 'img/7.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f63ef5",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db751744",
   "metadata": {},
   "source": [
    "<img src = 'img/8.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40b62b5",
   "metadata": {},
   "source": [
    "```python\n",
    "tokenizer = AutoTokenizer.from_pretrained('skt/kogpt2-base-v2', bos_token='</s>', eos_token='</s>', pad_token='<pad>')\n",
    "model = TFGPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2', from_pt=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1605cd45",
   "metadata": {},
   "source": [
    "```python\n",
    "def tokenize_df():\n",
    "    # 질문, 레이블 응답 문장을 불러옵니다.\n",
    "    for question, label, response in zip(df.question.to_list(),\n",
    "                                         df.label.to_list(), df.response.to_list()):\n",
    "        # 문장의 BOS token : </s>\n",
    "        bos_token = [tokenizer.bos_token_id]\n",
    "        # 문장의 EOS token : </s>\n",
    "        eos_token = [tokenizer.eos_token_id]\n",
    "        \n",
    "        #문장 구조 : BOS + 질문 + (토큰으로 구분) + 레이블 + (토큰으로 구분) + 응답 + EOS\n",
    "        sentence = tokenizer.encode('<unused0>' + question + '<unused1>' + label + '<unused2>' + response)\n",
    "        \n",
    "        yield bos_token + sentence + eos_token\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295ccc53",
   "metadata": {},
   "source": [
    "```python\n",
    "batch_size = 32\n",
    "\n",
    "# def 함수를 적용한 tf dataset을 만듭니다.\n",
    "dataset = tf.data.Dataset.from_generator(tokenize_df, output_types = tf.int32)\n",
    "\n",
    "# batch에서 가장 긴 문장을 기준으로 zero-padding을 진행합니다.\n",
    "dataset = dataset.padded_batch(batch_size = batch_size, padded_shapes=(None,),\n",
    "                               padding_values = tokenizer.pad_token_id)\n",
    "\n",
    "for batch in dataset:\n",
    "    break\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c650dd15",
   "metadata": {},
   "source": [
    "<img src = 'img/9.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c409e7",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce15a6c",
   "metadata": {},
   "source": [
    "```python\n",
    "#Hyperparameters\n",
    "\n",
    "EPOCHS = 20\n",
    "adam = tf.keras.optimizers.Adam(learning_rate = 3e-5, epsilon=1e-08)\n",
    "steps = len(df) // batch_size + 1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0392cdcd",
   "metadata": {},
   "source": [
    "```python\n",
    "# dataset을 batch_size으로 나눈 batch에서 loss를 계산한 후\n",
    "# tf.GradientTape으로 gradient을 계산하고\n",
    "# 계산한 gradient을 통해 adam(model)을 업데이트합니다.\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss = 0\n",
    "\n",
    "    try:\n",
    "        for batch in tqdm.notebook.tqdm(dataset, total = steps):\n",
    "            try:\n",
    "                with tf.GradientTape() as tape:\n",
    "                    result = model(batch, labels = batch)\n",
    "                    loss = result[0]\n",
    "                    batch_loss = tf.reduce_mean(loss, -1)\n",
    "      \n",
    "                grads = tape.gradient(batch_loss, model.trainable_variables)\n",
    "                adam.apply_gradients(zip(grads, model.trainable_variables))\n",
    "                train_loss += batch_loss / steps\n",
    "                \n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "    except:\n",
    "        pass\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c5e495",
   "metadata": {},
   "source": [
    "```python\n",
    "# save fine-tuned tokenizer & model\n",
    "\n",
    "tokenizer.save_pretrained('chatbot')\n",
    "model.save_pretrained('chatbot')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c829110e",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10634470",
   "metadata": {},
   "source": [
    "<img src = 'img/10.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09946fdd",
   "metadata": {},
   "source": [
    "```python\n",
    "# load fine-tuned model\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('chatbot', bos_token='</s>', eos_token='</s>', pad_token='<pad>')\n",
    "model = TFGPT2LMHeadModel.from_pretrained('chatbot')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6154ab87",
   "metadata": {},
   "source": [
    "```python\n",
    "def chatbot(text):\n",
    "    # input sentence : \"질문\" / 레이블 + 응답\n",
    "    sentence = '<unused0>' + text + '<unused1>'\n",
    "    tokenized = [tokenizer.bos_token_id] + tokenizer.encode(sentence)\n",
    "    tokenized = tf.convert_to_tensor([tokenized])\n",
    "    \n",
    "    # 질문 문장으로 \"레이블 + 응답\" 토큰 생성\n",
    "    result = model.generate(tokenized, min_length = 50, max_length = 200, repetition_penalty = 0.8,\n",
    "                            do_sample = True, no_repeat_ngram_size = 3, temperature = 0.01,\n",
    "                            top_k = 5)\n",
    "    \n",
    "    output = tokenizer.decode(result[0].numpy().tolist())\n",
    "    response = output.split('<unused1> ')[1]\n",
    "    # 레이블 토큰 출력\n",
    "    label = response.split('<unused2> ')[0]\n",
    "    # 응답 토큰 생성\n",
    "    response = response.split('<unused2> ')[1].replace('</s>', '')\n",
    "    \n",
    "    return label, response\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e18bed",
   "metadata": {},
   "source": [
    "<img src = 'img/0.png' width = '70%'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5478283",
   "metadata": {},
   "source": [
    "## Revision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f517f600",
   "metadata": {},
   "source": [
    "<img src = 'img/11.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e5940c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
